#!/usr/bin/env ruby

require "bundler"
Bundler.require(:default)
Dotenv.load

require_relative "lib/render"

renderer = Render.new

PROMPT = "Who won the Formula 1 2025 Japanese Grand Prix? You can use the Wikipedia for the 2025 Japenese Grand Prix: https://en.wikipedia.org/wiki/2025_Japanese_Grand_Prix"

request = <<~JSON
{
  "model": "#{ENV["INFERENCE_MODEL_ID"]}",
  "messages": [
    {
      "role": "user",
      "content": "#{PROMPT}"
    }
  ],
  "tools": [
    {
      "type": "heroku_tool",
      "function": {
        "name": "web_browsing_single_page"
      }
    }
  ],
  "tool_choice": "auto"
}
JSON

renderer.heroku_print("Here is the request we are sending to Heroku for inferencing...")

renderer.print_markdown(
  <<~MARKDOWN
  ```json
  #{request}
  ```
  MARKDOWN
)

full_request = <<~JSON
{
  "model": "#{ENV["INFERENCE_MODEL_ID"]}",
  "messages": [
   {
     "role": "user",
     "content": "#{PROMPT}"
   }
  ],
  "tools": [
   {
     "type": "function",
     "function": {
       "name": "web_browsing_single_page",
       "description": "Visits a single URL and returns the content of the web page as Markdown text.",
       "parameters": {
         "type": "object",
         "properties": {
           "url": {
             "type": "string",
             "description": "The URL to visit"
           }
         },
         "required": [
           "url"
         ]
       }
     }
   }
  ],
  "tool_choice": "auto",
  "stream": true
}
JSON

answer = renderer.confirm("Ready to see the full OpenAI-style request?")
exit(0) unless answer

renderer.print_markdown(
  <<~MARKDOWN
  ```json
  #{full_request}
  ```
  MARKDOWN
)

answer = renderer.confirm("Ready to send the inference request?")
exit(0) unless answer

renderer.inference_request(request:)

renderer.hr
